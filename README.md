# MCP Demo: Self-Hosted AI Pipeline for Privacy-First Applications

A demonstration of how Model Context Protocol (MCP) enables secure, self-hosted AI services that keep sensitive data within trusted environments. This weather service demo showcases the architectural patterns needed for privacy-critical applications like Rider Spoke.

## ðŸŽ¯ Core Demonstration

This project proves the viability of self-hosted AI pipelines by:

- Running local LLMs (Llama 3.2, Falcon3) without external API dependencies
- Implementing secure tool integration via MCP protocol
- Processing real-time data while maintaining privacy boundaries
- Demonstrating modular, API-driven architecture suitable for creative applications